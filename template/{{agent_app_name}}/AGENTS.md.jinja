## Overview

Agent in this template are built using **LangGraph** and inherit from the `LangGraphAgent` base class. This provides a standardized structure for creating agents that integrate with DataRobot's deployment infrastructure.

## Dependecies Installation

Should be ran after agent code modification:

```shell
dr task run {{ agent_app_name }}:install
```

## Agent Structure

Agent must be implemented in the following location withing the `{{ agent_app_name }}/agent` directory. None of the other files outside of this directory are related.

{% if agent_template_framework == "crewai" %}

Agent must implement the following components:

### 1. Class Definition

```python
from crewai import LLM, Agent, Task
from datarobot_genai.crewai.agent import (
    build_llm,
)
from datarobot_genai.crewai.base import CrewAIAgent

class MyAgent(CrewAIAgent):
    """Your agent description here."""
```

**Important**: `MyAgent` class should NOT be renamed!

### 2. Required Properties and Methods in Class Definition

#### `llm()` Method

**CRITICAL**: Do NOT modify, delete, or change this method. It MUST be kept exactly as shown below in the agent implementation:

```python
def llm(
        self,
        preferred_model: str | None = None,
        auto_model_override: bool = True,
    ) -> LLM:
        model = preferred_model or self.default_model
        if auto_model_override and not self.config.use_datarobot_llm_gateway:
            model = self.default_model
        if self.verbose:
            print(f"Using model: {model}")
        return build_llm(
            api_base=self.api_base,
            api_key=self.api_key,
            model=model,
            deployment_id=self.config.llm_deployment_id,
            timeout=self.timeout,
        )
```

**Why this is required**: This method handles model configuration, API authentication, and DataRobot LLM Gateway integration. Changing it will break deployment.

#### `agents` Property
Defines the list of sub-agents

```python
@property
def agents(self) -> List[Agent]:
        return [self.agent_1, self.agent_2]
```

#### `tasks` Property
Defines the list of tasks for the sub-agents

```python
@property
def tasks(self) -> List[Task]:
        return [self.task_1, self.task_2]
```


### 4. Agent tools

**IMPORTANT**: Add required tools in the `{{ agent_app_name }}/agent` directory. Do not add/modify any files outside of this directory. If some of the tools require adding new packages, they should be added to the pyproject.toml and properly installed using command

```shell
dr task run {{ agent_app_name }}:install
```

**IMPORTANT**: Tools must be imported and used in `MyAgent` implementation.


### 5. Preferred LLM model

Preferred model should be set in each ```self.llm(preferred_model="{preffered_model_here}")``` invocation.
**Important**: `preferred_model` parameter must be prefixed with `datarobot/`.

{% elif agent_template_framework == "langgraph" %}

Agent must implement the following components:

### 1. Class Definition

```python
from datarobot_genai.langgraph.agent import LangGraphAgent

class MyAgent(LangGraphAgent):
    """Your agent description here."""
```

**Important**: `MyAgent` class should NOT be renamed!

### 2. Required Properties and Methods in Class Definition

#### `llm()` Method

**CRITICAL**: Do NOT modify, delete, or change this method. It MUST be kept exactly as shown below in the agent implementation:

```python
def llm(
    self,
    preferred_model: str | None = None,
    auto_model_override: bool = True,
) -> ChatLiteLLM:
    api_base = self.litellm_api_base(config.llm_deployment_id)
    model = preferred_model
    if preferred_model is None:
        model = config.llm_default_model
    if auto_model_override and not config.use_datarobot_llm_gateway:
        model = config.llm_default_model
    if self.verbose:
        print(f"Using model: {model}")
    return ChatLiteLLM(
        model=model,
        api_base=api_base,
        api_key=self.api_key,
        timeout=self.timeout,
        streaming=True,
        max_retries=3,
    )
```

**Why this is required**: This method handles model configuration, API authentication, and DataRobot LLM Gateway integration. Changing it will break deployment.

#### `workflow` Property
Defines the agent's execution flow using LangGraph's StateGraph.

```python
@property
def workflow(self) -> StateGraph[MessagesState]:
    langgraph_workflow = StateGraph[
        MessagesState, None, MessagesState, MessagesState
    ](MessagesState)

    # Add nodes for each agent component
    langgraph_workflow.add_node("agent_node", self.agent_node)

    # Define edges (workflow connections)
    langgraph_workflow.add_edge(START, "agent_node")
    langgraph_workflow.add_edge("agent_node", END)

    return langgraph_workflow  # type: ignore[return-value]
```

#### `prompt_template` Property

Use it to define how user prompt is formatted for the agent.

```python
@property
def prompt_template(self) -> ChatPromptTemplate:
    return ChatPromptTemplate.from_messages([
        ("user", "{user_prompt_content}"),
    ])
```

**IMPORTANT**: The template must accept `{user_prompt_content}` to receive user prompts.

### 3. Agent Nodes

Agent nodes are typically created using `create_react_agent`.
**IMPORTANT**: Use `create_react_agent` call to create agent's node while passing the preferred LLM, system prompt and required tools into it.

```python
@property
def agent_node(self) -> Any:
    return create_react_agent(
        self.llm(preferred_model="datarobot/azure/gpt-4o-mini"),
        tools=self.tools,  # or [] for no tools
        prompt=make_system_prompt(
            "Your agent's system prompt here."
        ),
    )
```

### 4. Agent tools

**IMPORTANT**: Add required tools in the `{{ agent_app_name }}/agent` directory. Do not add/modify any files outside of this directory. If some of the tools require adding new packages, they should be added to the pyproject.toml and properly installed using command

```shell
dr task run {{ agent_app_name }}:install
```

**IMPORTANT**: Tools must be imported and used in `MyAgent` implementation.


### 5. Preferred LLM model

Preferred model should be set in each ```self.llm(preferred_model="{preffered_model_here}")``` invocation.
**Important**: `preferred_model` parameter must be prefixed with `datarobot/`.

{% elif agent_template_framework == "llamaindex" %}

Agent must implement the following components:

### 1. Class Definition

```python
from datarobot_genai.core.agents import extract_user_prompt_content
from datarobot_genai.llama_index import (
    DataRobotLiteLLM,
)
from datarobot_genai.llama_index.base import LlamaIndexAgent
from llama_index.core.agent.workflow import (
    AgentWorkflow,
    FunctionAgent,
)
from llama_index.core.workflow import Context

class MyAgent(LlamaIndexAgent):
    """Your agent description here."""
```

**Important**: `MyAgent` class should NOT be renamed!

### 2. Required Properties and Methods in Class Definition

#### `llm()` Method

**CRITICAL**: Do NOT modify, delete, or change this method. It MUST be kept exactly as shown below in the agent implementation:

```python
def llm(
        self,
        preferred_model: str | None = None,
        auto_model_override: bool = True,
    ) -> DataRobotLiteLLM:
        api_base = self.litellm_api_base(self.config.llm_deployment_id)
        model = preferred_model
        if preferred_model is None:
            model = self.default_model
        if auto_model_override and not self.config.use_datarobot_llm_gateway:
            model = self.default_model
        if self.verbose:
            print(f"Using model: {model}")
        return DataRobotLiteLLM(
            model=model,
            api_base=api_base,
            api_key=self.api_key,
            timeout=self.timeout,
        )
```

**Why this is required**: This method handles model configuration, API authentication, and DataRobot LLM Gateway integration. Changing it will break deployment.

#### `make_input_message` Method
Makes input message for the LLM

```python
def make_input_message(self, completion_create_params: Any) -> str:
        user_prompt_content = extract_user_prompt_content(completion_create_params)
        return (
            f"Your task is to write a concise report on a topic. "
            f"The topic is '{user_prompt_content}'. Make sure you find any interesting and relevant "
            f"information given the current year is {str(datetime.now().year)}. "
            f"Keep the final report under 500 words and don't overthink - this is a simple example task."
        )
```

**IMPORTANT**: The template must accept `{user_prompt_content}` to receive user prompts.

#### `extract_response_text` Method
Extracts LLM response.

```python
def extract_response_text(self, result_state: Any, events: list[Any]) -> str:
        return str(result_state["report_content"])
```

#### `build_workflow` Method
Builds agent workflow.

```python
def build_workflow(self) -> AgentWorkflow:
        return AgentWorkflow(
            agents=[self.agent_1, self.agent_2],
            root_agent=self.agent_1.name,
            initial_state={
                "planner_notes": {},
                "report_content": "Not finished yet.",
            },
        )
```


### 4. Agent tools

**IMPORTANT**: Add required tools in the `{{ agent_app_name }}/agent` directory. Do not add/modify any files outside of this directory. If some of the tools require adding new packages, they should be added to the pyproject.toml and properly installed using command

```shell
dr task run {{ agent_app_name }}:install
```

**IMPORTANT**: Tools must be imported and used in `MyAgent` implementation.


### 5. Preferred LLM model

Preferred model should be set in each ```self.llm(preferred_model="{preffered_model_here}")``` invocation.
**Important**: `preferred_model` parameter must be prefixed with `datarobot/`.

{% elif agent_template_framework == "nat" %}

Agent must implement the following components:

### 1. Class Definition

```python
from datarobot_genai.nat.agent import NatAgent

class MyAgent(NatAgent):
    """Your agent description here."""
```

**Important**: `MyAgent` class should NOT be renamed!

### 2. Required Properties and Methods in Class Definition

#### `__init__` Method

**CRITICAL**: Do NOT modify, delete, or change this method. It MUST be kept exactly as shown below in the agent implementation:

```python
def __init__(
        self,
        api_key: str | None = None,
        api_base: str | None = None,
        model: str | None = None,
        verbose: bool | str | None = True,
        timeout: int | None = 90,
        **kwargs: Any,
    ) -> None:
        super().__init__(
            workflow_path=Path(__file__).parent / "workflow.yaml",
            api_key=api_key,
            api_base=api_base,
            model=model,
            verbose=verbose,
            timeout=timeout,
            **kwargs,
        )
```

### 3. Agent Workflow

Change agent workflow in the  workflow.yaml file.

{% else %}

Agent must implement the following components:

### 1. Class Definition

```python
from datarobot_genai.core.agents import (
    BaseAgent,
    InvokeReturn,
    UsageMetrics,
    default_usage_metrics,
    extract_user_prompt_content,
    is_streaming,
)
from openai.types.chat import CompletionCreateParams

class MyAgent(BaseAgent[None]):
    """Your agent description here."""
```

**Important**: `MyAgent` class should NOT be renamed!

### 2. Required Properties and Methods in Class Definition

#### `invoke()` Method

Run the agent with the provided completion parameters.
[THIS METHOD IS REQUIRED FOR THE AGENT TO WORK WITH DRUM SERVER]


{% endif -%}


## Agent Testing

Run the following shell commands to run the agent locally:

```shell
dr task run {{ agent_app_name }}:lint
```

```shell
dr task run {{ agent_app_name }}:test
```

## Post Deployment Validation

Run the following shell command to validate the agent after deployment. If the response has no errors then the deployment is successful.

```shell
task agent:cli -- execute-deployment --user_prompt "Agent specific prompt to validate that it's working" --deployment_id <deployment_id>
```
